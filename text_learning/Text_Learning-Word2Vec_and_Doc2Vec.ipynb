{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eca4c0e-b325-4a6d-909c-e07ba1c1f963",
   "metadata": {},
   "source": [
    "In this notebook, we will move from numeric data to text. In the last year, text has received a lot of attention due to the buzz around ChatGPT. We are going to start a bit simpler by looking at two older approaches for extracting meaning from text: 1) `word2vec` and 2) `doc2vec`. The following code block imports libraries we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0b679-01b1-4fab-b1da-9752951a7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "from pprint import pprint\n",
    "import re\n",
    "import string\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a97e3-394f-41d4-938b-819fa2ae9659",
   "metadata": {},
   "source": [
    "The following code block reads in the data we will consider, which is a dataset of abstracts for scholarly publications related to human trafficking, labor trafficking, and sex trafficking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731c232-528a-4f24-9173-8c1b0ffc82c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = pathlib.Path('abstract_data.json')\n",
    "\n",
    "if data_filepath.exists():\n",
    "    with open(data_filepath) as fin:\n",
    "        data = json.load(fin)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a671eb7-7a7b-405f-9c01-94f45c5b7abc",
   "metadata": {},
   "source": [
    "The following code block prints an example of the data for one entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7012bced-7171-486b-8584-269e7724d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = list(data.keys())\n",
    "\n",
    "pprint(data[id_list[75]], width=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3598a660-20b0-47a5-995e-1276f2d74d8b",
   "metadata": {},
   "source": [
    "The following code block defines a simple function for cleaning the abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e2bc2-82b2-4eb7-9d38-2d77518873cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(text):\n",
    "    text = text.replace('\\n',' ').strip()\n",
    "    text = text.lower()\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    text = text.split(' ')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da83d82-b101-41ce-9daa-d4fbe871ec02",
   "metadata": {},
   "source": [
    "The following code block demonstrates the function. As you can see, it is very rudimentary. If we were doing an analysis for production or a research project, I would invest much more effort in cleaning the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e511d50-66cb-41c2-b89d-d680e5e2bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_text(data[id_list[75]]['abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ee40e-6a60-4f4d-a465-9ada32b3da7c",
   "metadata": {},
   "source": [
    "The following code block applies the function to the data, creating a new `clean_abstract` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2fe6e-0828-4827-9f05-0f55ac3b8888",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tqdm(data, 'Cleaning abstracts'):\n",
    "    data[key]['clean_abstract'] = prepare_text(data[key]['abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c7ade-8372-4380-9ff8-6bfd834f065b",
   "metadata": {},
   "source": [
    "The following code block prints an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320865fe-6954-4a0b-8ebb-5fbde8e8e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(data[id_list[75]], width=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb609d9-fbe6-4ee0-81e5-5c344e8942f7",
   "metadata": {},
   "source": [
    "#### Word2Vec\n",
    "\n",
    "We will first look at Word2Vec. See https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html for additional details. The following code block creates a list of the cleaned abstracts for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae44abbe-1302-40c1-bf1a-320d73ad6170",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = [val['clean_abstract'] for val in data.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e2507-3b97-40cc-9e45-c18ecbb6ecb0",
   "metadata": {},
   "source": [
    "The following code block uses `gensim` to fit a `Word2Vec` model using the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf5042-a3e9-4883-9fb0-4bd9f13a8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences=abstracts,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911d9eb-31e4-44ad-a2ec-9b31edfd16b0",
   "metadata": {},
   "source": [
    "By default, the model uses a *Continuous Bag of Words* training scheme to determine 100-dimensional vector representations for words. A few examples are given in the following code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0becad51-873a-4479-bbff-ebc927b6b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv['pimp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd4a1f-2585-480a-b5ea-66bbdb475dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv['trafficker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb80312-1407-4e52-878d-fa6b53eb0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv['victim']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fae782-8e28-4ce6-ae2d-fca1f8a9ca7a",
   "metadata": {},
   "source": [
    "The following code block defines some test cases we can use to understand what is captured in the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233cefaa-0c24-4c17-a318-2d587537f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_test_cases(w2v_model_object):\n",
    "\n",
    "    pimp_trafficker_similarity = cosine_similarity(\n",
    "        w2v_model_object.wv['pimp'].reshape(1, -1), \n",
    "        w2v_model_object.wv['trafficker'].reshape(1, -1)\n",
    "    )[0][0]\n",
    "    print(f' - pimp/trafficker similarity: {pimp_trafficker_similarity:.5f}')\n",
    "\n",
    "    pimp_victim_similarity = cosine_similarity(\n",
    "        w2v_model_object.wv['pimp'].reshape(1, -1), \n",
    "        w2v_model_object.wv['victim'].reshape(1, -1)\n",
    "    )[0][0]\n",
    "    print(f' - pimp/victim similarity: {pimp_victim_similarity:.5f}')\n",
    "\n",
    "    trafficker_most_similar = w2v_model_object.wv.most_similar(\n",
    "        positive=['trafficker'], \n",
    "        topn=5,\n",
    "    )\n",
    "    print('\\n - trafficker (most similar)')\n",
    "    pprint(trafficker_most_similar, indent=4)\n",
    "\n",
    "    victim_most_similar = w2v_model_object.wv.most_similar(\n",
    "        positive=['victim'], \n",
    "        topn=5,\n",
    "    )\n",
    "    print('\\n - victim (most similar)')\n",
    "    pprint(victim_most_similar, indent=4)\n",
    "\n",
    "    internet_most_similar = w2v_model_object.wv.most_similar(\n",
    "        positive=['internet'], \n",
    "        topn=5,\n",
    "    )\n",
    "    print('\\n - internet (most similar)')\n",
    "    pprint(internet_most_similar, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a99bdb-419e-4b62-a6a0-bc981b60b709",
   "metadata": {},
   "source": [
    "The following code block uses the function to examine the outputs for the model we previously fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad23d40-79e9-41ec-818e-f5319e6e8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_test_cases(w2v_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79329f0c-d07f-405d-a6dc-d8b4c6ea3dcb",
   "metadata": {},
   "source": [
    "The following code block fits another model with a larger *window* size and number of *epochs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f105538-9cc8-498a-988e-ea46af827af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences=abstracts, \n",
    "    window=10,\n",
    "    epochs=25,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83c45b1-0105-4add-bd74-4a8ba6ccc1fb",
   "metadata": {},
   "source": [
    "Test results are computed in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8484b881-b178-44b3-9c6c-462b67ee8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_test_cases(w2v_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0760d46c-4d42-4b44-9f74-609d5f1bf975",
   "metadata": {},
   "source": [
    "The following code block fits another model that uses a *skip-gram* training scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5282c3-5b01-404d-9fe9-2c78fbc4585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences=abstracts, \n",
    "    window=10,\n",
    "    epochs=25,\n",
    "    sg=1,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa1b17-4b36-4622-8a7d-f4abf8d40243",
   "metadata": {},
   "source": [
    "Test results are computed in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc4c349-3e9c-45ea-9f99-e6f4e1d2629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_test_cases(w2v_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495adc9c-559c-47cc-87b6-f5fdff3c7421",
   "metadata": {},
   "source": [
    "#### Doc2Vec\n",
    "\n",
    "We will now look at *Doc2Vec*. Doc2Vec trains a set of *paragraph vectors*, one for each document, in addition to the word vectors. To implement this in `gensim`, we need to use `TaggedDocument` objects. These are defined in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2350cb85-bdb7-4719-a477-1a865f202f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(val['clean_abstract'], [key]) for key, val in data.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54edbb1f-1e59-4820-976c-99f01a42711f",
   "metadata": {},
   "source": [
    "The following code block trains a basic `Doc2Vec` model using the *gensim* defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c6efe-9170-4a5e-a999-d09b10607bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = Doc2Vec(\n",
    "    documents=documents,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72141493-954c-4e9f-9e48-0fe3d24a2ba0",
   "metadata": {},
   "source": [
    "Since Doc2Vec still computes word vectors, we can still perform our tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8e440-cef4-4af5-83a7-0c1b4cf20a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_test_cases(d2v_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f934cd5-b197-4628-950d-54ac0caa8a1d",
   "metadata": {},
   "source": [
    "We can get the *paragraph vector* for a document by indexing with the ID we used when defining the `TaggedDocument` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397335b-a35e-4290-a06d-42f275065719",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.dv[id_list[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c04aa2-8a64-4b73-8e82-074636fbccd7",
   "metadata": {},
   "source": [
    "We can use the paragraph vectors to identify similar pieces of text. To demonstrate, here are the IDS for two papers I have been involved with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4550eb9b-c390-42f7-81e4-aabef8d247ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ids = [\n",
    "    'SCOPUS_ID:85147005648', \n",
    "    'SCOPUS_ID:85097137525',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f87ce-3a4d-45c4-a91d-96306b58b481",
   "metadata": {},
   "source": [
    "As you might expect, the Doc2Vec model finds them to be very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a20dcb-18fd-4dd6-8fd8-faff45e53f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(\n",
    "    d2v_model.dv[my_ids[0]].reshape(1, -1),\n",
    "    d2v_model.dv[my_ids[1]].reshape(1, -1),\n",
    ")[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014cf81-0fc7-459d-9d90-5c251ca93d61",
   "metadata": {},
   "source": [
    "We can use the `most_similar` method to easily get back a list of the IDs for the most similar documents along with the similarity score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1584009b-ef16-413d-998a-5bee54098079",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.dv.most_similar(d2v_model.dv[my_ids[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4eb9a-3cda-4133-9bf1-51a1edd2764d",
   "metadata": {},
   "source": [
    "The following code block prints the titles for the most similar 25 documents for both of the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230ff10-bd92-44ce-a0f7-7ff4002b1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in my_ids:\n",
    "    target_paper = data[target]['title']\n",
    "    abstract = data[target]['abstract']\n",
    "    print(f\"Target: {target_paper}\\n\")\n",
    "    print(f\"Abstract: {abstract}\")\n",
    "    print('\\n')\n",
    "    for sid, similarity in d2v_model.dv.most_similar(d2v_model.dv[target], topn=25):\n",
    "        print(f\" - {data[sid]['title']} ({similarity: .3f})\")\n",
    "    print('*'*100 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e5bad-5ad7-4d0b-980b-cb494b0c853f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e569cb-63ff-4421-addc-c1ed87f5e84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
